{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from dsicl.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gq/anaconda3/envs/DS-ICL/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = \"../model/llama_1.3b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, padding_side=\"right\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).half().to(torch.device('cuda'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集，用get_data_reader方法从一个json文件中读取，json文件格式要求如下：\n",
    "{ \\\n",
    "   'data_info':{\\\n",
    "    'data_name': 'rte_train',\\\n",
    "    'label_space': ['entailment', 'not_entailment'],\\\n",
    "    'columns': ['premise', 'hypothesis', 'label']\\\n",
    "   },\\\n",
    "   'data':[\\\n",
    "    sample1,\\\n",
    "    sample2,\\\n",
    "    ...\\\n",
    "   ]\\\n",
    "}\\\n",
    "\\\n",
    "读取数据时传入label_map参数，将标签从默认标签转换为想要的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_reader import get_data_reader, DataReader, read_demo_benchmark\n",
    "task = 'cr'\n",
    "trainset, testset = read_demo_benchmark(task=task, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"the extended zoom range and faster lense put it at the top of it 's class .\",\n",
       " 'label': 'positive'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prompter import Prompter\n",
    "from src.template import DEMO_TEMPLATE, DEMO_HEAD\n",
    "template = DEMO_TEMPLATE[task]\n",
    "head = DEMO_HEAD[task]\n",
    "\n",
    "prompter = Prompter(template=template, head=head, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the reviews based on whether their sentiment type is positive or negative.\n",
      "\n",
      "Review:it 's not as stylized as a sony or samsung .\n",
      "Sentiment:negative\n",
      "\n",
      "Review:the 6600 will provide similar service in more developed areas of the states and not as well in more remote areas .\n",
      "Sentiment:negative\n",
      "\n",
      "Review:a ) feel cheap -- the plastic is feels like it would break very easily , and it definately wouldnt survive a drop\n",
      "Sentiment:\n"
     ]
    }
   ],
   "source": [
    "print(prompter.generate_context(trainset[:2], testset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ranker import DEmORanker\n",
    "set_seed(0)\n",
    "original_demos = trainset.get_subset(8, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'unlike other reviewers , i have found the support to be responsive , almost no wait time on the phone , and relatively knowledgeable .',\n",
       "  'label': 'positive'},\n",
       " {'sentence': \"the best thing to do with this version , is to leave it on the store shelf . it doesn 't work , and will cost you an enormous amount of your time , not to mention your hard earned dollars .\",\n",
       "  'label': 'negative'},\n",
       " {'sentence': 'they have the worst service of any of the major companies .',\n",
       "  'label': 'negative'},\n",
       " {'sentence': ') no locked-in proprietary business like apple ; . this baby plays wmas too .',\n",
       "  'label': 'positive'},\n",
       " {'sentence': 'the manual is easy to understand , and it is mostly idiot proof .',\n",
       "  'label': 'positive'},\n",
       " {'sentence': 'unfortunately , i sold it exactly a month later .',\n",
       "  'label': 'negative'},\n",
       " {'sentence': \"1 . the diaper champ doesn 't require special refills that are expensive and hard to find ! .\",\n",
       "  'label': 'positive'},\n",
       " {'sentence': 'the volume level of the phone is not all that good .',\n",
       "  'label': 'negative'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = DEmORanker(model, tokenizer, prompter, trainset.data_info['label_space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,  4134,  1598,   278, 21804,  2729,   373,  3692,  1009, 19688,\n",
      "          1134,   338,  6374,   470,  8178, 29889,    13,    13,  1123,  1493,\n",
      "         29901,   348,  4561,   916,  9076,   414,  1919,   474,   505,  1476,\n",
      "           278,  2304,   304,   367,  5544,   573,  1919,  4359,   694,  4480,\n",
      "           931,   373,   278,  9008,  1919,   322, 13774,  7134,   519,   869,\n",
      "            13, 29903,   296,  2073, 29901,  1066,  3321,    13,    13,  1123,\n",
      "          1493, 29901, 29896,   869,   278,  9766,   546, 18480,  1838,   525,\n",
      "         29873,  1996,  4266,  2143,  6090,   393,   526, 19390,   322,  2898,\n",
      "           304,  1284,  1738,   869,    13, 29903,   296,  2073, 29901,  1066,\n",
      "          3321,    13,    13,  1123,  1493, 29901,  1552,  1900,  2655,   304,\n",
      "           437,   411,   445,  1873,  1919,   338,   304,  5967,   372,   373,\n",
      "           278,  3787,   528,   761,   869,   372,  1838,   525, 29873,   664,\n",
      "          1919,   322,   674,  3438,   366,   385, 18886,   681,  5253,   310,\n",
      "           596,   931,  1919,   451,   304,  3585,   596,  2898, 20591, 17208,\n",
      "           869,    13, 29903,   296,  2073, 29901, 22198,    13,    13,  1123,\n",
      "          1493, 29901,  1552,  7977,  3233,   310,   278,  9008,   338,   451,\n",
      "           599,   393,  1781,   869,    13, 29903,   296,  2073, 29901, 22198,\n",
      "            13,    13,  1123,  1493, 20925,   694, 22822, 29899,   262, 24440,\n",
      "           653,  5381,   763, 26163,  2056,   869,   445, 24354, 13582,   281,\n",
      "          8247,  2086,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,\n",
      "            13,    13,  1123,  1493, 29901,   348,  7524,  1919,   474,  5239,\n",
      "           372,  3721,   263,  4098,  2678,   869,    13, 29903,   296,  2073,\n",
      "         29901, 22198,    13,    13,  1123,  1493, 29901,  1552, 12219,   338,\n",
      "          4780,   304,  2274,  1919,   322,   372,   338, 11149,  1178, 24414,\n",
      "          5296,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,    13,\n",
      "            13,  1123,  1493, 29901, 19562,   505,   278, 17322,  2669,   310,\n",
      "           738,   310,   278,  4655, 14582,   869,    13, 29903,   296,  2073,\n",
      "         29901, 22198,    13,    13,  1123,  1493, 10834, 29940, 29914, 29909,\n",
      "         29962,    13, 29903,   296,  2073, 29901]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n",
      "{'input_ids': tensor([[   1, 8178],\n",
      "        [   1, 6374]], device='cuda:0'), 'attention_mask': tensor([[1, 1],\n",
      "        [1, 1]], device='cuda:0')}\n",
      "[tensor([    1,  4134,  1598,   278, 21804,  2729,   373,  3692,  1009, 19688,\n",
      "         1134,   338,  6374,   470,  8178, 29889,    13,    13,  1123,  1493,\n",
      "        29901,   348,  4561,   916,  9076,   414,  1919,   474,   505,  1476,\n",
      "          278,  2304,   304,   367,  5544,   573,  1919,  4359,   694,  4480,\n",
      "          931,   373,   278,  9008,  1919,   322, 13774,  7134,   519,   869,\n",
      "           13, 29903,   296,  2073, 29901,  1066,  3321,    13,    13,  1123,\n",
      "         1493, 29901, 29896,   869,   278,  9766,   546, 18480,  1838,   525,\n",
      "        29873,  1996,  4266,  2143,  6090,   393,   526, 19390,   322,  2898,\n",
      "          304,  1284,  1738,   869,    13, 29903,   296,  2073, 29901,  1066,\n",
      "         3321,    13,    13,  1123,  1493, 29901,  1552,  1900,  2655,   304,\n",
      "          437,   411,   445,  1873,  1919,   338,   304,  5967,   372,   373,\n",
      "          278,  3787,   528,   761,   869,   372,  1838,   525, 29873,   664,\n",
      "         1919,   322,   674,  3438,   366,   385, 18886,   681,  5253,   310,\n",
      "          596,   931,  1919,   451,   304,  3585,   596,  2898, 20591, 17208,\n",
      "          869,    13, 29903,   296,  2073, 29901, 22198,    13,    13,  1123,\n",
      "         1493, 29901,  1552,  7977,  3233,   310,   278,  9008,   338,   451,\n",
      "          599,   393,  1781,   869,    13, 29903,   296,  2073, 29901, 22198,\n",
      "           13,    13,  1123,  1493, 20925,   694, 22822, 29899,   262, 24440,\n",
      "          653,  5381,   763, 26163,  2056,   869,   445, 24354, 13582,   281,\n",
      "         8247,  2086,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,\n",
      "           13,    13,  1123,  1493, 29901,   348,  7524,  1919,   474,  5239,\n",
      "          372,  3721,   263,  4098,  2678,   869,    13, 29903,   296,  2073,\n",
      "        29901, 22198,    13,    13,  1123,  1493, 29901,  1552, 12219,   338,\n",
      "         4780,   304,  2274,  1919,   322,   372,   338, 11149,  1178, 24414,\n",
      "         5296,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,    13,\n",
      "           13,  1123,  1493, 29901, 19562,   505,   278, 17322,  2669,   310,\n",
      "          738,   310,   278,  4655, 14582,   869,    13, 29903,   296,  2073,\n",
      "        29901, 22198,    13,    13,  1123,  1493, 10834, 29940, 29914, 29909,\n",
      "        29962,    13, 29903,   296,  2073, 29901,  8178], device='cuda:0'), tensor([    1,  4134,  1598,   278, 21804,  2729,   373,  3692,  1009, 19688,\n",
      "         1134,   338,  6374,   470,  8178, 29889,    13,    13,  1123,  1493,\n",
      "        29901,   348,  4561,   916,  9076,   414,  1919,   474,   505,  1476,\n",
      "          278,  2304,   304,   367,  5544,   573,  1919,  4359,   694,  4480,\n",
      "          931,   373,   278,  9008,  1919,   322, 13774,  7134,   519,   869,\n",
      "           13, 29903,   296,  2073, 29901,  1066,  3321,    13,    13,  1123,\n",
      "         1493, 29901, 29896,   869,   278,  9766,   546, 18480,  1838,   525,\n",
      "        29873,  1996,  4266,  2143,  6090,   393,   526, 19390,   322,  2898,\n",
      "          304,  1284,  1738,   869,    13, 29903,   296,  2073, 29901,  1066,\n",
      "         3321,    13,    13,  1123,  1493, 29901,  1552,  1900,  2655,   304,\n",
      "          437,   411,   445,  1873,  1919,   338,   304,  5967,   372,   373,\n",
      "          278,  3787,   528,   761,   869,   372,  1838,   525, 29873,   664,\n",
      "         1919,   322,   674,  3438,   366,   385, 18886,   681,  5253,   310,\n",
      "          596,   931,  1919,   451,   304,  3585,   596,  2898, 20591, 17208,\n",
      "          869,    13, 29903,   296,  2073, 29901, 22198,    13,    13,  1123,\n",
      "         1493, 29901,  1552,  7977,  3233,   310,   278,  9008,   338,   451,\n",
      "          599,   393,  1781,   869,    13, 29903,   296,  2073, 29901, 22198,\n",
      "           13,    13,  1123,  1493, 20925,   694, 22822, 29899,   262, 24440,\n",
      "          653,  5381,   763, 26163,  2056,   869,   445, 24354, 13582,   281,\n",
      "         8247,  2086,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,\n",
      "           13,    13,  1123,  1493, 29901,   348,  7524,  1919,   474,  5239,\n",
      "          372,  3721,   263,  4098,  2678,   869,    13, 29903,   296,  2073,\n",
      "        29901, 22198,    13,    13,  1123,  1493, 29901,  1552, 12219,   338,\n",
      "         4780,   304,  2274,  1919,   322,   372,   338, 11149,  1178, 24414,\n",
      "         5296,   869,    13, 29903,   296,  2073, 29901,  1066,  3321,    13,\n",
      "           13,  1123,  1493, 29901, 19562,   505,   278, 17322,  2669,   310,\n",
      "          738,   310,   278,  4655, 14582,   869,    13, 29903,   296,  2073,\n",
      "        29901, 22198,    13,    13,  1123,  1493, 10834, 29940, 29914, 29909,\n",
      "        29962,    13, 29903,   296,  2073, 29901,  6374], device='cuda:0')]\n",
      "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m demos_l \u001b[38;5;241m=\u001b[39m [ranker\u001b[38;5;241m.\u001b[39mrank(original_demos, d, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m testset]\n",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m demos_l \u001b[38;5;241m=\u001b[39m [\u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_demos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m testset]\n",
      "File \u001b[0;32m~/DSICL/src/ranker/demo_ranker.py:55\u001b[0m, in \u001b[0;36mDEmORanker.rank\u001b[0;34m(self, demos, sample, num, seed)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         candidate_orders \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(demos),\u001b[38;5;28mlen\u001b[39m(demos),replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration_num)]\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_demos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_orders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m influence_l \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_demos):\n",
      "File \u001b[0;32m~/DSICL/src/ranker/demo_ranker.py:39\u001b[0m, in \u001b[0;36mDEmORanker.stage_1\u001b[0;34m(self, demos, orders)\u001b[0m\n\u001b[1;32m     37\u001b[0m         content_free_sample[key] \u001b[38;5;241m=\u001b[39m token\n\u001b[1;32m     38\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompter\u001b[38;5;241m.\u001b[39mgenerate_context([demos[_] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m order], content_free_sample)\n\u001b[0;32m---> 39\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m content_free_entropy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy(probs)\n\u001b[1;32m     41\u001b[0m content_free_probs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m probs\n",
      "File \u001b[0;32m~/DSICL/src/model.py:179\u001b[0m, in \u001b[0;36mspeculative_decoder.decode\u001b[0;34m(self, prefix, answer_list)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs_ids)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs_attention_mask)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# inputs = self.tokenizer(prompts,max_length=truncation_l, truncation=True, padding= True, return_tensors=\"pt\").to(self.model.device)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# print(inputs)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:torch\u001b[38;5;241m.\u001b[39mstack(inputs_ids), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:torch\u001b[38;5;241m.\u001b[39mstack(inputs_attention_mask)}\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# demos_l = [ranker.rank(original_demos, d, seed=0) for d in testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化一个inferencer进行推理，目前支持direct inferencer（利用推测解码直接获取label上的概率）和generation inferencer（常规的自回归生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inferencer import DirectInferencer\n",
    "\n",
    "labels = trainset.data_info['label_space']\n",
    "\n",
    "direct_inferencer = DirectInferencer(model, tokenizer, prompter, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对整个测试集推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:06<00:00, 42.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative', 'positive', 'negative', 'negative', 'negative']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_p = direct_inferencer.batch_infer(demos_l, testset)\n",
    "# y_p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_inferencer.infer(original_demos, testset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:07<00:00, 36.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative', 'negative', 'negative', 'negative', 'negative']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_yp = direct_inferencer.batch_infer([original_demos] * len(testset), testset)\n",
    "baseline_yp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以调用Evaluator类对结果进行评估（暂时只支持accuracy和f1-score，可以自己拓展）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluator import Evaluator\n",
    "y_t = [testset[_]['label'] for _ in range(len(testset))]\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390625"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.acc_evaluate(baseline_yp, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.acc_evaluate(y_p, y_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
